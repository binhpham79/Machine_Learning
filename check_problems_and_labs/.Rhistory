head(X_train)
head(X_test)
head(Y_train)
head(Y_test)
Y_train <- to_categorical(Y_train, 2)
Y_train <- Y[i]
Y_test <- Y[-i]
Y_train <- to_categorical(Y_train, 2)
Y_train <- to_categorical(Y_train, levels(Y_train))
head(Y)
head(Y_train)
levels(Y_train)
?to_categorical()
Y_train <- to_categorical(Y_train)
Y_test <- to_categorical(Y_test)
head(Y_train)
levels(Y)
Y_train <- Y[i]
Y_train <- to_categorical(Y_train, 2)
Y_train <- to_categorical(Y_train, num_classes=2)
Y_train <- to_categorical(Y_train)
Y_test <- to_categorical(Y_test)
model <- keras_model_sequential()
model %>%
layer_dense(units=16,  activation='relu', input_shape = dim(X_train)[[2]]) %>%
#layer_dense(units=8, activation='relu') %>%
layer_dense(units=1, activation='sigmoid')
model %>% compile(
loss = 'binary_crossentropy',
optimizer = 'rmsprop',
metrics = c('accuracy')
)
model %>% fit(X_train, Y_train, epochs=4, batch_size=1, verbose=1)
Y_train <- Y[i]
Y_test <- Y[-i]
model <- keras_model_sequential()
model %>%
layer_dense(units=16,  activation='relu', input_shape = dim(X_train)[[2]]) %>%
#layer_dense(units=8, activation='relu') %>%
layer_dense(units=1, activation='sigmoid')
model %>% compile(
loss = 'binary_crossentropy',
optimizer = 'rmsprop',
metrics = c('accuracy')
)
model %>% fit(X_train, Y_train, epochs=4, batch_size=1, verbose=1)
model <- keras_model_sequential()
model %>%
layer_dense(units=16,  activation='relu', input_shape = dim(X_train)[[2]]) %>%
#layer_dense(units=8, activation='relu') %>%
layer_dense(units=1, activation='sigmoid')
model %>% compile(
loss = 'binary_crossentropy',
optimizer = 'rmsprop',
metrics = c('accuracy')
)
model %>% fit(X_train, Y_train, epochs=4, batch_size=10, verbose=1)
results <- model %>% evaluate(X_test, Y_test, verbose=0)
results
pred <- predict(model, X_test)
table(pred, Y_test)
#############################################
# 13.2
# load wine data  6497 x 12
wine <- read.csv("wine_all.csv", header=TRUE)
wine <- wine[,-c(1,5,6,7,9)]
str(wine)
N <- nrow(wine)
p <- ncol(wine)
t <- 8             # target is type
X <- wine[, -t]
Y <- wine[, t]
# train and test
set.seed(1234)
i <- sample(1:nrow(wine), .8*nrow(wine), replace=FALSE)
X_train <- data.matrix(X[i, -t])
Y_train <- Y[i]
X_test <- data.matrix(X[-i, -t])
Y_test <- Y[-i]
# normalize data
means <- apply(X_train, 2, mean)
stdvs <- apply(X_train, 2, sd)
X_train <- scale(X_train, center=means, scale=stdvs)
X_test <- scale(X_test, center=means, scale=stdvs)
Y_train <- to_categorical(Y_train)
Y_test <- to_categorical(Y_test)
model <- keras_model_sequential()
model %>%
layer_dense(units=16,  activation='relu', input_shape = dim(X_train)[[2]]) %>%
#layer_dense(units=8, activation='relu') %>%
layer_dense(units=1, activation='sigmoid')
model %>% compile(
loss = 'binary_crossentropy',
optimizer = 'rmsprop',
metrics = c('accuracy')
)
model %>% fit(X_train, Y_train, epochs=4, batch_size=10, verbose=1)
head(Y_train)
Y_train <- Y[i]
Y_test <- Y[-i]
Y_train <- to_categorical(Y_train, 2)
head(Y_train)
Y_train <- to_categorical(as.integer(Y_train), 2)
#############################################
# 13.2
# load wine data  6497 x 12
wine <- read.csv("wine_all.csv", header=TRUE)
str(wine)
N <- nrow(wine)
p <- ncol(wine)
t <- 13             # target is type
X <- wine[, -t]
Y <- wine[, t]
# train and test
set.seed(1234)
i <- sample(1:nrow(wine), .8*nrow(wine), replace=FALSE)
X_train <- data.matrix(X[i, -t])
Y_train <- Y[i]
X_test <- data.matrix(X[-i, -t])
Y_test <- Y[-i]
# normalize data
means <- apply(X_train, 2, mean)
stdvs <- apply(X_train, 2, sd)
X_train <- scale(X_train, center=means, scale=stdvs)
X_test <- scale(X_test, center=means, scale=stdvs)
Y_train <- to_categorical(Y_train, 2)
#############################################
# 13.2
# load wine data  6497 x 12
library(keras)
Y_train <- to_categorical(Y_train, 2)
Y_train <- to_categorical(Y_train, levels(Y_train))
Y_train <- to_categorical(Y_train, length(levels(Y_train)))
Y_train <- to_categorical(Y_train, 2)
head(Y)
as.integer(head(Y))
as.integer(tail(Y))
Y <- wine[, t]
Y <- Y - 1
Y_train <- Y[i]
Y <- as.integer(Y) - 1
Y_train <- Y[i]
Y_test <- Y[-i]
Y_train <- to_categorical(Y_train, 2)
Y <- wine[, t]
Y <- as.integer(Y)
Y <- Y - 1L
Y_train <- Y[i]
Y_test <- Y[-i]
Y_train <- to_categorical(Y_train, 2)
Y_test <- to_categorical(Y_test, 2)
# build a model
model <- keras_model_sequential()
model %>%
layer_dense(units=16,  activation='relu', input_shape = dim(X_train)[[2]]) %>%
#layer_dense(units=8, activation='relu') %>%
layer_dense(units=1, activation='sigmoid')
model %>% compile(
loss = 'binary_crossentropy',
optimizer = 'rmsprop',
metrics = c('accuracy')
)
model %>% fit(X_train, Y_train, epochs=4, batch_size=1, verbose=1)
head(Y_train)
dim(X_train)
# build a model
model <- keras_model_sequential()
model %>%
layer_dense(units=16,  activation='relu', input_shape = dim(X_train)[[2]]) %>%
#layer_dense(units=8, activation='relu') %>%
layer_dense(units=2, activation='sigmoid')
model %>% compile(
loss = 'binary_crossentropy',
optimizer = 'rmsprop',
metrics = c('accuracy')
)
model %>% fit(X_train, Y_train, epochs=4, batch_size=1, verbose=1)
results <- model %>% evaluate(X_test, Y_test, verbose=0)
results
pred <- predict(model, X_test)
table(pred, Y_test)
results
head(pred)
pred <- ifelse(pred[,1] > 0.5, 1, 2)
table(pred, Y_test)
head(pred)
pred(Y_test)
head(Y_test)
tail(Y_test)
Y_test <- Y[-i]
table(pred, Y_test)
mean(pred==Y_test)
head(pred)
head(Y_test)
Y_test <- Y_test + 1L
table(pred, Y_test)
mean(pred==Y_test)
pred <- predict(model, X_test)
pred <- ifelse(pred[,1] > 0.5, 1, 2)
Y_test_fact <- Y[-i]
Y_test_fact <- Y_test_fact + 1L
table(pred, Y_test_fact)
mean(pred==Y_test_fact)
Y_test <- Y[-i]
Y_test <- to_categorical(Y_test, 2)
# build a model
model <- keras_model_sequential()
model %>%
layer_dense(units=16,  activation='relu', input_shape = dim(X_train)[[2]]) %>%
layer_dense(units=8, activation='relu') %>%
layer_dense(units=2, activation='sigmoid')
model %>% compile(
loss = 'binary_crossentropy',
optimizer = 'rmsprop',
metrics = c('accuracy')
)
model %>% fit(X_train, Y_train, epochs=10, batch_size=1, verbose=1)
mean(pred==Y_test_fact)
results <- model %>% evaluate(X_test, Y_test, verbose=0)
results
pred <- predict(model, X_test)
pred <- ifelse(pred[,1] > 0.5, 1, 2)
Y_test_fact <- Y[-i]
Y_test_fact <- Y_test_fact + 1L
table(pred, Y_test_fact)
mean(pred==Y_test_fact)
wine <- read.csv("wine_all.csv", header=TRUE)
str(wine)
# train and test
set.seed(1234)
i <- sample(1:nrow(wine), .8*nrow(wine), replace=FALSE)
train <- wine[i,]
test <- wine[-i,]
# check distrib of white/red
summary(train$type)  # red 1284  white 3913
summary(test$type)   # red 315   white 985
# scale the data
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
train_norm <- as.data.frame(lapply(train[,1:12], normalize))
test_norm <- as.data.frame(lapply(test[,1:12], normalize))
#############################################
# try neural net
library(neuralnet)
train_norm <- cbind(train_norm, train[,13])
colnames(train_norm)[[13]] <- "type"
str(train_norm)
n <- length(train_norm$type)
x <- matrix(0, n, 2)  # 2 levels
x[(1L:n) + n * (unclass(train_norm$type) - 1L)] <- 1
dimnames(x) <- list(names(train_norm$type), levels(train_norm$type))
train_norm <- cbind(train_norm[,-13], x)
str(train_norm)
n <- names(train_norm)
f <- as.formula(paste("red + white ~ ", paste(n[!n %in% c("red", "white")], collapse = " + ")))
set.seed(1234)
nn1 <- neuralnet(f, data=train_norm, hidden=c(16), act.fct="logistic", linear.output=FALSE, lifesign="full")
pred <- compute(nn1, test_norm[-13])
pred <- pred$net.result
head(pred)
pred <- ifelse(pred[,1] > 0.5, 1, 2)
mean(pred==as.integer(test$type))  # never above 0.5 pitiful
table(pred, as.integer(test$type))
head(pred)
head(test$type)
head(as.integer(test$type))
nn1 <- neuralnet(f, data=train_norm, hidden=c(16, 8), act.fct="logistic", linear.output=FALSE, lifesign="full")
pred <- compute(nn1, test_norm[-13])
pred <- pred$net.result
pred <- ifelse(pred[,1] > 0.5, 1, 2)
mean(pred==as.integer(test$type))
table(pred, as.integer(test$type))
nn1 <- neuralnet(f, data=train_norm, hidden=c(8), act.fct="logistic", linear.output=FALSE, lifesign="full")
pred <- compute(nn1, test_norm[-13])
pred <- pred$net.result
pred <- ifelse(pred[,1] > 0.5, 1, 2)
mean(pred==as.integer(test$type))
table(pred, as.integer(test$type))
nn1 <- neuralnet(f, data=train_norm, hidden=c(24, 8), act.fct="logistic", linear.output=FALSE, lifesign="full")
pred <- compute(nn1, test_norm[-13])
pred <- pred$net.result
pred <- ifelse(pred[,1] > 0.5, 1, 2)
mean(pred==as.integer(test$type))
table(pred, as.integer(test$type))
nn1 <- neuralnet(f, data=train_norm, hidden=c(32), act.fct="logistic", linear.output=FALSE, lifesign="full")
pred <- compute(nn1, test_norm[-13])
pred <- pred$net.result
pred <- ifelse(pred[,1] > 0.5, 1, 2)
mean(pred==as.integer(test$type))
table(pred, as.integer(test$type))
str(train)
?neuralnet()
nn1 <- neuralnet(f, data=train_norm, hidden=c(16), act.fct="logistic", err.fct="ce", linear.output=FALSE, lifesign="full")
pred <- compute(nn1, test_norm[-13])
pred <- pred$net.result
pred <- ifelse(pred[,1] > 0.5, 1, 2)
mean(pred==as.integer(test$type))
table(pred, as.integer(test$type))
nn1 <- neuralnet(f, data=train_norm, hidden=c(16, 2), act.fct="logistic", linear.output=FALSE, lifesign="full")
pred <- compute(nn1, test_norm[-13])
pred <- pred$net.result
pred <- ifelse(pred[,1] > 0.5, 1, 2)
mean(pred==as.integer(test$type))
table(pred, as.integer(test$type))
nn1 <- neuralnet(f, data=train_norm, hidden=c(16, 4), act.fct="logistic", linear.output=FALSE, lifesign="full")
pred <- compute(nn1, test_norm[-13])
pred <- pred$net.result
pred <- ifelse(pred[,1] > 0.5, 1, 2)
mean(pred==as.integer(test$type))
table(pred, as.integer(test$type))
nn1 <- neuralnet(f, data=train_norm, hidden=c(16, 12, 8), act.fct="logistic", linear.output=FALSE, lifesign="full")
pred <- compute(nn1, test_norm[-13])
pred <- pred$net.result
pred <- ifelse(pred[,1] > 0.5, 1, 2)
mean(pred==as.integer(test$type))
table(pred, as.integer(test$type))
nn1 <- neuralnet(f, data=train_norm, hidden=c(32, 16, 8, 4), act.fct="logistic", linear.output=FALSE, lifesign="full")
pred <- compute(nn1, test_norm[-13])
pred <- pred$net.result
pred <- ifelse(pred[,1] > 0.5, 1, 2)
mean(pred==as.integer(test$type))
table(pred, as.integer(test$type))
nn1 <- neuralnet(f, data=train_norm, hidden=c(32, 24, 16, 8, 4), act.fct="logistic", linear.output=FALSE, lifesign="full")
pred <- compute(nn1, test_norm[-13])
pred <- pred$net.result
pred <- ifelse(pred[,1] > 0.5, 1, 2)
mean(pred==as.integer(test$type))
table(pred, as.integer(test$type))
nn1 <- neuralnet(f, data=train_norm, hidden=c(16, 12, 8), act.fct="logistic", linear.output=FALSE, lifesign="full")
pred <- compute(nn1, test_norm[-13])
pred <- pred$net.result
pred <- ifelse(pred[,1] > 0.5, 1, 2)
mean(pred==as.integer(test$type))
table(pred, as.integer(test$type))
nn1 <- neuralnet(f, data=train_norm, hidden=c(16, 12, 8), act.fct="logistic", linear.output=FALSE, lifesign="full")
pred <- compute(nn1, test_norm[-13])
pred <- pred$net.result
pred <- ifelse(pred[,1] > 0.5, 1, 2)
mean(pred==as.integer(test$type))
table(pred, as.integer(test$type))
#############################################
# 12.1
# load wine data  6497 x 12
wine <- read.csv("wine_all.csv", header=TRUE)
str(wine)
# train and test
set.seed(1234)
i <- sample(1:nrow(wine), .8*nrow(wine), replace=FALSE)
train <- wine[i,]
test <- wine[-i,]
# scale the data
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
train_norm <- as.data.frame(lapply(train[,1:12], normalize))
test_norm <- as.data.frame(lapply(test[,1:12], normalize))
# try neural network
library(neuralnet)
str(train_norm)
n <- names(train_norm)
f <- as.formula(paste("quality ~ ", paste(n[!n %in% "quality"], collapse = " + ")))
set.seed(1234)
nn1 <- neuralnet(f, data=train_norm, hidden=c(9,6,3), linear.output = TRUE, threshold = 0.02, lifesign="full")
# evaluate
pred <- compute(nn1, test_norm[,-12])
pred <- pred$net.result
pred_unscale <- pred * (max(test$quality) - min(test$quality)) + min(test$quality)
cor_nn <- cor(pred_unscale, test$quality)
# evaluate
pred <- compute(nn1, test_norm[,-12])
pred <- pred$net.result
pred_unscale <- pred * (max(test$quality) - min(test$quality)) + min(test$quality)
cor_nn <- cor(pred_unscale, test$quality)
mse_nn <- mean((pred_unscale - test$quality)^2)
head(pred_unscale)
head(test$quality)
train_norm <- as.data.frame(lapply(train[,1:11], normalize))
test_norm <- as.data.frame(lapply(test[,1:11], normalize))
train_norm <- cbind(train_norm, train[,12])
str(train_norm)
colnames(train_norm[,12]) <- "quality"
colnames(train_norm[12]) <- "quality"
str(train_norm)
names(train_norm)
names(train_norm)[12]
names(train_norm)[12] <- "quality"
str(train_norm)
nn1 <- neuralnet(f, data=train_norm, hidden=c(9,6,3), linear.output = TRUE, threshold = 0.02, lifesign="full")
nn1 <- neuralnet(f, data=train_norm, hidden=c(9,6,2), linear.output = TRUE, threshold = 0.04, lifesign="full")
#############################################
# 8.1
# load wine data  6497 x 12
wine <- read.csv("wine_all.csv", header=TRUE)
str(wine)
# train and test
set.seed(1234)
i <- sample(1:nrow(wine), .8*nrow(wine), replace=FALSE)
train <- wine[i,]
test <- wine[-i,]
# check distrib of white/red
summary(train$type)  # red 1284  white 3913
summary(test$type)   # red 315   white 985
# try logistic regression to pick type based on all other columns
glm1 <- glm(type~., data=train, family=binomial)
summary(glm1)
probs <- predict(glm1, newdata=test, type="response")
pred <- ifelse(probs>0.5, 2, 1)
table(pred, test$type)
#pred red white
#   1 311     3
#   2   4   982
acc_glm <- mean(pred==as.integer(test$type))  # .994
# try knn
library(class)
knn_pred <- knn(train=train[.1:12], test=test[.1:12], cl=train$type, k=2)
table(knn_pred, test$type)
#knn_pred red white
#   red   275    44
#   white  40   941
acc_knn_unscaled <- mean(knn_pred==test$type)  # .935
#############################################
# 8.2
# scale the data
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x)))
}
train_norm <- as.data.frame(lapply(train[,1:12], normalize))
test_norm <- as.data.frame(lapply(test[,1:12], normalize))
knn_pred2 <- knn(train=train_norm, test=test_norm, cl=train$type, k=2)
table(knn_pred2, test$type)
#knn_pred2 red white
#    red   309    25
#    white   6   960
acc_knn_scaled <- mean(knn_pred2==test$type)  # 0.976
means <- apply(train, 2, mean)
means <- apply(train, 2, mean, na.rm=TRUE)
str(train)
apply(train, 2, mean)
sapply(x, train, sum(is.na(x)))
sapply(train, function(x) sum(is.na(x)==TRUE)
)
means <- sapply(train, 2, mean)
means <- apply(train, 2, mean)
?apply()
?sapply()
means <- sapply(train, mean)
stdvs <- sapply(train, sd)
str(rain)
str(train)
means <- sapply(train[,-13], mean)
stdvs <- sapply(train[,-13], sd)
train_scaled <- scale(train[,-13], center=means, scale=stdvs)
test_scaled <- scale(test[,-13], center=means, scale=stdvs)
knn_pred3 <- knn(train=train_scaled, test=test_scaled, cl=train$type, k=2)
mean(knn_pred3==test$type)
acc_knn_scale2 <- mean(knn_pred3==test$type)
# try with fewer predictors
train_reduced <- train_scaled[,c(2:8,11)]
test_reduced <- test_scaled[,c(2:8,11)]
knn_pred4 <- knn(train=train_reduced, test=test_reduced, cl=train$type, k=2)
table(knn_pred4, test$type)
#knn_pred3 red white
#    red   305   115
#    white  10   870
acc_knn4 <- mean(knn_pred4==test$type)  # 0.903
#############################################
# 8.3 kNN regression
train_reg <- train_scaled[,1:11]
test_reg <- test_scaled[,1:11]
library(caret)
fit <- knnreg(train_reg, train$quality, k=2)
predictions <- predict(fit, test_reg)
cor(predictions, test$quality) # 0.3988
mse <- mean((predictions - test$quality)^2) # 0.792
cor_knn <- cor(predictions, test$quality) # 0.3988
cor_mse <- mse <- mean((predictions - test$quality)^2) # 0.792
# compare to linear regression
train_reg2 <- cbind(train_reg, train$quality)
test_reg2 <- cbind(test_reg, test$quality)
lm1 <- lm(train$quality~., data=train_reg)
summary(lm1)
predictions2 <- predict(lm1, newdata=test_reg2)
cor_lm <- cor(predictions2, test$quality)  # 0.49
predictions2 <- predict(lm1, newdata=test_reg2)
lm1 <- lm(train$quality~., data=train_reg)
# compare to linear regression
train_reg2 <- cbind(train_reg, train$quality)
test_reg2 <- cbind(test_reg, test$quality)
lm1 <- lm(train$quality~., data=train_reg)
lm1 <- lm(train$quality~., data=train_reg2)
# compare to linear regression
train_reg2 <- as.data.frame(cbind(train_reg, train$quality))
test_reg2 <- as.data.frame(cbind(test_reg, test$quality))
lm1 <- lm(train$quality~., data=train_reg2)
summary(lm1)
predictions2 <- predict(lm1, newdata=test_reg2)
cor_lm <- cor(predictions2, test$quality)  # 0.49
mse_lm <- mean((predictions2 - test$quality)^2)   # 0.787
head(test$quality)
head(predictions2)
lm1 <- lm(train$quality~., data=train)
predictions2 <- predict(lm1, newdata=test)
cor_lm <- cor(predictions2, test$quality)  # 1
mse_lm <- mean((predictions2 - test$quality)^2)   # 0
head(train)
# compare to linear regression
lm1 <- lm(train$quality~.-type, data=train)
summary(lm1)
predictions2 <- predict(lm1, newdata=test)
cor_lm <- cor(predictions2, test$quality)  # 0.56
mse_lm <- mean((predictions2 - test$quality)^2)   # 0.53
